{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7551ebc5",
   "metadata": {},
   "source": [
    "CLINICALBERT + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f95bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from transformers import AutoTokenizer, AutoModel, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Disable wandb and suppress warnings\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ðŸš€ Using device: {device}\")\n",
    "\n",
    "# Load tokenizer and base model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Load and preprocess dataset\n",
    "file_path = \"/content/drive/MyDrive/textual_data/TEXTUAL_DATA/processed_disorder_symptoms.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# Map frequency and label\n",
    "frequency_mapping = {\n",
    "    \"Very frequent (99-80%)\": 4,\n",
    "    \"Frequent (79-30%)\": 3,\n",
    "    \"Occasional (29-5%)\": 2,\n",
    "    \"Very rare (<4-1%)\": 1\n",
    "}\n",
    "df[\"frequency\"] = df[\"frequency\"].map(frequency_mapping)\n",
    "label_mapping = {label: idx for idx, label in enumerate(df[\"disorder\"].unique())}\n",
    "df[\"label\"] = df[\"disorder\"].map(label_mapping)\n",
    "\n",
    "# Dataset class\n",
    "class SymptomDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "        return {**{k: v.squeeze() for k, v in encoding.items()}, \"labels\": torch.tensor(label, dtype=torch.long)}\n",
    "\n",
    "# Train-validation split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"symptom\"].tolist(), df[\"label\"].tolist(), test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = SymptomDataset(train_texts, train_labels)\n",
    "val_dataset = SymptomDataset(val_texts, val_labels)\n",
    "\n",
    "# Load classification model\n",
    "fine_tuned_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(label_mapping)).to(device)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./clinicalbert_model\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    lr_scheduler_type=\"linear\",\n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=fine_tuned_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "# Get embeddings\n",
    "def get_fine_tuned_bert_embeddings(text_list):\n",
    "    inputs = tokenizer(text_list, padding=True, truncation=True, return_tensors=\"pt\", max_length=256).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = fine_tuned_model.bert(**inputs)\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].to(\"cpu\")\n",
    "    mean_pooling = torch.mean(outputs.last_hidden_state, dim=1).to(\"cpu\")\n",
    "    combined_embedding = torch.cat((cls_embedding, mean_pooling), dim=1)\n",
    "    return combined_embedding.numpy()\n",
    "\n",
    "# Compute embeddings\n",
    "symptom_embeddings = np.array([get_fine_tuned_bert_embeddings([symptom])[0] for symptom in df[\"symptom\"]])\n",
    "\n",
    "# Combine features\n",
    "X = np.hstack((symptom_embeddings, df[\"frequency\"].values.reshape(-1, 1)))\n",
    "y = df[\"disorder\"]\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "svm_model = SVC(kernel=\"rbf\", C=50, gamma=\"scale\", class_weight=\"balanced\", probability=True, random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"âœ… Fine-Tuned ClinicalBERT + SVM Accuracy: {accuracy:.2f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Prediction function\n",
    "def predict_disease(symptom_text, frequency_text):\n",
    "    frequency_value = frequency_mapping.get(frequency_text, 1)\n",
    "    symptom_vector = get_fine_tuned_bert_embeddings([symptom_text])\n",
    "    input_features = np.hstack((symptom_vector, np.array([[frequency_value]])))\n",
    "    input_features = scaler.transform(input_features)\n",
    "    predicted_disorder = svm_model.predict(input_features)[0]\n",
    "    return predicted_disorder\n",
    "\n",
    "# Test prediction\n",
    "test_symptom = \"Short neck\"\n",
    "test_frequency = \"Very frequent (99-80%)\"\n",
    "predicted_disease = predict_disease(test_symptom, test_frequency)\n",
    "print(f\"ðŸ©º Predicted Disease: {predicted_disease}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
