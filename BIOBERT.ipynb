{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "532a6c7a",
   "metadata": {},
   "source": [
    "BIOBERT + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a810b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1️⃣ Load data\n",
    "file_path = '/content/drive/My Drive/textual_data/TEXTUAL_DATA/augmented_disorder_symptoms_1000.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 2️⃣ Encode target labels\n",
    "le = LabelEncoder()\n",
    "df['disorder_encoded'] = le.fit_transform(df['disorder'])\n",
    "\n",
    "# 3️⃣ Load BioBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "\n",
    "# 4️⃣ Generate BioBERT embeddings using Mean Pooling + Add frequency\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    token_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    mean_embedding = token_embeddings.mean(dim=0).numpy()\n",
    "    return mean_embedding\n",
    "\n",
    "print(\"⚡ Generating BioBERT embeddings with frequency...\")\n",
    "\n",
    "embeddings = []\n",
    "for i, row in df.iterrows():\n",
    "    symptom = str(row['symptom'])\n",
    "    freq = float(row['frequency_num']) if not pd.isna(row['frequency_num']) else 0.0\n",
    "    emb = get_embedding(symptom)\n",
    "    combined = np.append(emb, freq)  # Append frequency as a feature\n",
    "    embeddings.append(combined)\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "\n",
    "# 5️⃣ Train-test split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    embeddings,\n",
    "    df['disorder_encoded'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['disorder_encoded']\n",
    ")\n",
    "\n",
    "# 6️⃣ Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 7️⃣ Train SVM Classifier\n",
    "print(\"⚡ Training SVM Classifier...\")\n",
    "svm = SVC(kernel='rbf', C=10, gamma='scale', random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 8️⃣ Evaluate\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"✅ Final Accuracy (SVM): {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n✅ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3b76cb",
   "metadata": {},
   "source": [
    "BIOBERT + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d57ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1️⃣ Load data\n",
    "file_path = '/content/drive/My Drive/textual_data/TEXTUAL_DATA/augmented_disorder_symptoms_1000.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 2️⃣ Encode target labels\n",
    "le = LabelEncoder()\n",
    "df['disorder_encoded'] = le.fit_transform(df['disorder'])\n",
    "\n",
    "# 3️⃣ Load BioBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "\n",
    "# 4️⃣ Generate BioBERT embeddings\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # [CLS] token embedding\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "    return cls_embedding\n",
    "\n",
    "print(\"⚡ Generating BioBERT embeddings (this might take a few mins)...\")\n",
    "embeddings = np.array([get_embedding(str(s)) for s in df['symptom']])\n",
    "\n",
    "# 5️⃣ Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, df['disorder_encoded'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 6️⃣ Train Random Forest\n",
    "print(\"⚡ Training Random Forest...\")\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 7️⃣ Evaluate\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"✅ Final Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n✅ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
